Требования сегодняшнего дня: приложения должны иметь высокую доступность и обеспечивать низкое время отклика даже при высокой нагрузке.
##  Модель «поток на запрос»

Традиционный способ разработки веб-приложения с помощью Spring – это использование MVC и его развертывание в контейнере сервлетов, таком как Tomcat. Контейнер сервлетов имеет выделенный пул потоков для обработки HTTP- запросов, где каждому входящему запросу будет назначен поток, и этот поток будет обрабатывать весь жизненный цикл запроса (**модель «поток на запрос»**). По умолчанию для сервера Tomcat установлено 200 подключений.

Это означает, что приложение сможет обрабатывать количество одновременных запросов, равное размеру пула потоков. Можно настроить размер пула потоков, но поскольку каждый поток резервирует некоторую память (обычно 1 МБ), чем больший размер пула потоков мы настраиваем, тем выше потребление памяти.

Если приложение разработано в соответствии с архитектурой на основе микросервисов, то у нас есть лучшие возможности для масштабирования в зависимости от нагрузки, но за **высокое использование памяти по-прежнему приходится платить** (потоки часто блокируются в ожидании ответа от другой службы, что приводит к огромной трате ресурсов).
## Ожидание операций ввода/вывода

Такой же тип потерь также возникает при ожидании завершения других типов операций ввода-вывода, таких как вызов базы данных или чтение из файла. Во всех этих ситуациях поток, выполняющий запрос ввода-вывода, будет заблокирован и будет ожидать, пока операция ввода-вывода не будет завершена, это называется *блокирующим вводом-выводом*.
Такие ситуации, когда выполняющийся поток блокируется, просто ожидая ответа, означают потерю потоков и, следовательно, потерю памяти (рисунок слева).

![[Блокирующий ввод вывод.png]]
## Время ответа
Другой проблемой традиционного императивного программирования является **время отклика**, когда службе необходимо выполнить более одного запроса ввода-вывода (рисунок справа). Например, службе A может потребоваться вызвать службы B и C, а также выполнить **поиск в базе данных**, а затем вернуть в результате некоторые агрегированные данные.

Это будет означать, что время ответа службы A, помимо времени ее обработки, будет суммой следующих значений: 
- время отклика услуги B (задержка сети + обработка) 
- время отклика службы C (задержка сети + обработка) 
- время ответа на запрос к базе данных (сетевая задержка + обработка)

Если нет никакой реальной логической причины выполнять эти вызовы последовательно, то, безусловно, если эти вызовы будут выполняться параллельно, это очень положительно повлияет на время отклика службы А.

## Перегрузка клиента
Другой тип проблемы, которая может возникнуть в ландшафте микросервисов, — когда сервис A запрашивает некоторую информацию у сервиса B, скажем, например, обо всех заказах, размещенных в течение последнего месяца. Если количество заказов окажется огромным, для службы А может возникнуть проблема получить всю эту информацию сразу. Служба A может быть перегружена большим объемом данных, что может привести, например, к ошибке нехватки памяти.

**Все эти проблемы решает реактивное программирование.**
## Реактивное программирование
Перечислим преимущества:
- отходим от модели «поток на запрос» и можем обрабатывать больше запросов с небольшим количеством потоков 
- предотвращаем блокировку потоков при ожидании завершения операций ввода- вывода 
- упрощаем параллельные вызовы 
- поддерживаем «обратное давление», давая клиенту возможность сообщить серверу, с какой нагрузкой он может справиться

>[!Defenition]
>Реактивное программирование - это асинхронность, соединенная с потоковой обработкой данных

![[Развитие многопоточности Java.png]]

## [[Реактивное программирование Java]]
